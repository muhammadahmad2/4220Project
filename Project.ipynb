{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eigenfaces(object):                                                       # *** COMMENTS ***\n",
    "    faces_count = 11\n",
    "\n",
    "    faces_dir = '.'                                                             # directory path to the AT&T faces\n",
    "\n",
    "    l = 2211                                       # training images count\n",
    "    m = 92                                                                      # number of columns of the image\n",
    "    n = 112                                                                     # number of rows of the image\n",
    "    mn = m * n                                                                  # length of the column vector\n",
    "    \n",
    "    def __init__(self, _energy = 0.85):\n",
    "        print('> Initializing started')\n",
    "\n",
    "        self.energy = _energy\n",
    "        self.training_ids = []                                                  # train image id's for every at&t face\n",
    "\n",
    "        L = np.empty(shape=(self.mn, self.l), dtype='float64')                  # each row of L represents one train image\n",
    "\n",
    "\n",
    "        test_images = []\n",
    "        labels = []\n",
    "\n",
    "\n",
    "        i = 0\n",
    "        a = 0            \n",
    "        for imgfolder in os.listdir('./data/train/'):\n",
    "            for filename in os.listdir('./data/train/' + imgfolder):\n",
    "                filename = './data/train/' + imgfolder + '/'+ filename\n",
    "                if (filename.lower().endswith(('.png', '.jpg', '.jpeg'))):\n",
    "                    img=cv2.imread(filename,0)\n",
    "\n",
    "                    img = cv2.resize(img, (92,112), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                    img_col = np.array(img, dtype='float64').flatten()              # flatten the 2d image into 1d\n",
    "\n",
    "                    L[:, i] = img_col[:]                                      # set the cur_img-th column to the current training image\n",
    "                    \n",
    "                    i += 1\n",
    "\n",
    "                                           \n",
    "\n",
    "        self.mean_img_col = np.sum(L, axis=1) / self.l                          # get the mean of all images / over the rows of L\n",
    "\n",
    "        for j in range(0, self.l):                                             # subtract from all training images\n",
    "            L[:, j] -= self.mean_img_col[:]\n",
    "\n",
    "        C = np.matrix(L.transpose()) * np.matrix(L)                             # instead of computing the covariance matrix as\n",
    "        C /= self.l                                                             # L*L^T, we set C = L^T*L, and end up with way\n",
    "                                                                                # smaller and computentionally inexpensive one\n",
    "                                                                                # we also need to divide by the number of training\n",
    "                                                                                # images\n",
    "\n",
    "        self.evalues, self.evectors = np.linalg.eig(C)                          # eigenvectors/values of the covariance matrix\n",
    "        sort_indices = self.evalues.argsort()[::-1]                             # getting their correct order - decreasing\n",
    "        self.evalues = self.evalues[sort_indices]                               # puttin the evalues in that order\n",
    "        self.evectors = self.evectors[sort_indices]                             # same for the evectors\n",
    "\n",
    "        evalues_sum = sum(self.evalues[:])                                      # include only the first k evectors/values so\n",
    "        evalues_count = 0                                                       # that they include approx. 85% of the energy\n",
    "        evalues_energy = 0.0\n",
    "        for evalue in self.evalues:\n",
    "            evalues_count += 1\n",
    "            evalues_energy += evalue / evalues_sum\n",
    "\n",
    "            if evalues_energy >= self.energy:\n",
    "                break\n",
    "\n",
    "        self.evalues = self.evalues[0:evalues_count]                            # reduce the number of eigenvectors/values to consider\n",
    "        self.evectors = self.evectors[0:evalues_count]\n",
    "\n",
    "        self.evectors = self.evectors.transpose()                               # change eigenvectors from rows to columns\n",
    "        self.evectors = L * self.evectors                                       # left multiply to get the correct evectors\n",
    "        norms = np.linalg.norm(self.evectors, axis=0)                           # find the norm of each eigenvector\n",
    "        self.evectors = self.evectors / norms                                   # normalize all eigenvectors\n",
    "\n",
    "        self.W = self.evectors.transpose() * L                                  # computing the weights\n",
    "\n",
    "        print('> Initializing ended')\n",
    "\n",
    "        \n",
    "    def classify(self, img):\n",
    "        #img = cv2.imread(path_to_img, 0)\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.equalizeHist(gray)\n",
    "\n",
    "        lower_reso = cv2.pyrDown(img)\n",
    "\n",
    "        #for im in lower_reso:\n",
    "\n",
    "        img = cv2.resize(img,(92, 112), interpolation = cv2.INTER_AREA)                                       # read as a grayscale image\n",
    "        img_col = np.array(img, dtype='float64').flatten()                      # flatten the image\n",
    "        img_col -= self.mean_img_col                                            # subract the mean column\n",
    "        img_col = np.reshape(img_col, (self.mn, 1))                             # from row vector to col vector\n",
    "\n",
    "        S = self.evectors.transpose() * img_col                                 # projecting the normalized probe onto the\n",
    "                                                                                # Eigenspace, to find out the weights\n",
    "\n",
    "        diff = self.W - S                                                       # finding the min ||W_j - S||\n",
    "        \n",
    "        norms = np.linalg.norm(diff, axis=0)\n",
    "        \n",
    "        closest_face_id = np.argmin(norms)                                      # the id [0..240) of the minerror face to the sample\n",
    "        return closest_face_id+1\n",
    "            #if(closest_face_id<38):\n",
    "            #    return True                   # return the faceid (1..40)\n",
    "        #return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Initializing started\n",
      "> Initializing ended\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    efaces = Eigenfaces()                                       # create the Eigenfaces object with the data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    cam = cv2.VideoCapture('./inter.mpg')\n",
    "    \n",
    "    \n",
    "    liv = efaces.classify(cv2.imread('./478.jpg'))\n",
    "    if((liv >= 1489) & (liv <= 1881)):\n",
    "        print(\"True\")\n",
    "\n",
    "    while True:\n",
    "        ret, img = cam.read()\n",
    "\n",
    "\n",
    "        #img = cv2.imread('./ben.jpg')\n",
    "        vis = img.copy()\n",
    "\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        x = 92\n",
    "        y = 112\n",
    "\n",
    "        egg = efaces.classify(vis)\n",
    "        if((egg >= 1489) & (egg <= 1881)):\n",
    "            vis[0 : 20, 0 : 20] = (255,255,255)\n",
    "\n",
    "        #w = 0\n",
    "        #for a in range(width):\n",
    "        #    h = 0\n",
    "        #    for b in range(height):\n",
    "        #        temp = img[h : h + y, w : w + x]\n",
    "\n",
    "        #        if(efaces.classify(temp) == True):\n",
    "        #            vis[h : h + y, w : w + x] = (255,255,255)\n",
    "        #            break;\n",
    "        #        h += 5\n",
    "        #        if((h + y)>height):\n",
    "        #            break\n",
    "        #    w += 5\n",
    "        #    if((w + x)>width):\n",
    "        #        break\n",
    "\n",
    "\n",
    "        cv2.imshow('facedetect', vis)\n",
    "\n",
    "        if 0xFF & cv2.waitKey(5) == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
